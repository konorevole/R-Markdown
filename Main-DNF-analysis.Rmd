---
title: "Main DNF Analysis"
author: "Kathleen Onorevole"
date: "August 18, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Remember to set working directory**

Load the packages required for these analyses. Also source the functions script.
```{r libraries}

library(plyr)
library(dplyr)
library(ggplot2)
library(ggpmisc)
library(lmtest)
library(car)
library(MASS)

source("functions.R")

```

Read in relevant data sets. These should all be taken from the CLEAN folders, which are housed in my master R Markdown folder. The raw data have been processed in separate R Markdown documents; see those files for details. Each parameter has its own folder within the parent folder.
```{r read.in}

all.N2 <- read.csv("N2-flux\\clean\\N2-flux-by-core_with-summer15.csv", header = T, stringsAsFactors = F)

DNE <- read.csv("DNE\\clean\\DNE-clean_no-summer15_all-sites.csv", header = T, stringsAsFactors = F)

```

Set the distinguishing labels as factors and implementing the preferred order. Uses set.factors function written by me.
Also eliminate Summer 2015 and Lo/Hi Ref cores as neither will be used in basic thesis analysis. (Do not match sampling scheme and thereby mess up statistics.) Will deal with these in a separate R Markdown doc if necessary.
```{r order.variables}

#Uses basic factor settings to input NA for Lo/Hi Ref and Summer 2015 cores
all.N2 <- set.factors.basic(all.N2)

all.N2$Age <- as.numeric(all.N2$Age)
all.N2$Habitat <- factor(all.N2$Habitat, levels = c("oyster", "marsh", "Ref"))

#Eliminate Lo/Hi Ref and Summer 2015 by getting rid of NAs
basic.N2 <- na.omit(all.N2)

DNE <- set.factors.basic(DNE)
DNE <- na.omit(DNE)

```

Begin by exploring original N2 flux data set for normal distribution and heteroskedasticity. Essentially, every measure fails. Includes code at end added in March 2017 to check for normality of residuals.
```{r normal.checks}

#Fails Bartlett Test when grouped by Site and Season; Habitat is ok
bartlett.test(N2Flux ~ Site, data = basic.N2)
bartlett.test(N2Flux ~ Season, data = basic.N2)
bartlett.test(N2Flux ~ Habitat, data = basic.N2)

#Interestingly, passes Levene Test for Site and Habitat; fails for Season (change 2nd parameter after ~ to explore)- this is probably b/c the Levene test is less sensitive
leveneTest(N2Flux ~ Site, data = basic.N2)

#Boxplot looks ok but there are definite outliers (change 2nd parameter as above)
boxplot(N2Flux ~ Season, data = basic.N2)

#All seasons except winter fail Shapiro-Wilk test
test.norm.Season <- basic.N2 %>%
  group_by(Season) %>%
  summarise(SW.pvalue = shapiro.test(N2Flux)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

#All sites except Carrot fail Shapiro-Wilk
test.norm.Site <- basic.N2 %>%
  group_by(Site) %>%
  summarise(SW.pvalue = shapiro.test(N2Flux)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

#Histograms do not appear normal (again, change grouping parameter if desired)
basic.N2 %>%
  ggplot(aes(N2Flux)) +
  geom_histogram(stat = "bin", binwidth = 5) +
  facet_grid(Season ~ .)

#QQ plot lines by Site are not satisfactorily straight
p1 <- ggplot(basic.N2)
p1 + stat_qq(aes(sample = N2Flux, colour = Site)) + geom_smooth(aes(colour = Site), method = "lm")


#Below section added in March 2017 during review of ANOVA assumptions, after realizing that normality check should be on residuals, not raw data.

#Checking untransformed N2 fluxes with 3-way interactive setup for normality of RESIDUALS check
basic.model <- lm(N2Flux ~ Season * Site * CoreName, data = basic.N2)
resids.basic <- residuals(basic.model)
qqnorm(resids.basic)
qqline(resids.basic)

#Fails Shapiro test when set up for normality of RESIDUALS. Passes Levene.
shapiro.test(resids.basic)
leveneTest(N2Flux ~ Season * Site * CoreName, data = basic.N2)

#Setting up similar as before, but now 2-way with just Season & Site
basic.model2 <- lm(N2Flux ~ Season * Site, data = basic.N2)
resids.basic2 <- residuals(basic.model2)
qqnorm(resids.basic2)
qqline(resids.basic2)

#Still fails Shapiro, and also Levene
shapiro.test(resids.basic2)
leveneTest(N2Flux ~ Season * Site, data = basic.N2)

```

Normality checks largely failed. Various transformations were attempted (see failed.transformations section of this R Markdown doc) and I ultimately decided to use the Box Cox transformation. The below code identifies the optimal lambda value, applies the transformation, and checks for normality/heteroskedasticity.
See end for code added in March 2017 to address the normality of residuals rather than the raw data.
```{r BoxCox.transform}

#Start by finding the optimal value of lambda

#Create a column with positive values of N2 by adding 21 to each flux
positive.N2 <- mutate(basic.N2,
                  PosN2 = N2Flux + 21)
#Create a log-likelihood graph using a command from the MASS package
bctrans <- boxcox(PosN2 ~ Age, data = positive.N2,
                    lambda = seq(0, 1, by = 0.1))
#Identify the maximum likelihood value
which.max(bctrans$y)
#Use that maximum likelihood value (from the y axis) to determine the associated lambda (on the x axis)
bctrans$x[which.max(bctrans$y)]

#Take the variable to the power of the lambda to perform the transformation!
BC.N2 <- mutate(positive.N2,
                     N2BoxCox = (((PosN2 ^ 0.454) - 1) / 0.454))

#Calculate transformed N2 flux values by core type
BC.N2.type <- ddply(BC.N2, c("Season", "Site", "CoreName", "Habitat", "Age"), summarise,
                         Avg_N2BoxCox = mean(N2BoxCox))

#Histogram and QQ plots look much better
hist(BC.N2$N2BoxCox)
qqnorm(BC.N2$N2BoxCox)
qqline(BC.N2$N2BoxCox)

#I believe this plot visualizes the variance, which looks more even
plot(BC.N2$N2BoxCox)

#Visualizing the regression with the Box Cox transformation
reg1 <- lm(N2BoxCox ~ Age, BC.N2)
par(mfrow = c(2,2))
plot(reg1)

#Transformed values pass Bartlett Test except for when grouped by Site (p = 0.01)
#Pass Levene Test for every grouping
#Change grouping variable after ~ to view various outcomes
bartlett.test(N2BoxCox ~ Habitat, BC.N2)
leveneTest(N2BoxCox ~ Habitat, BC.N2)

#Transformed data passes Shapiro-Wilk test for all groupings except Army & oysters
BC.norm.Season <- BC.N2 %>%
  group_by(Season) %>%
  summarise(SW.pvalue = shapiro.test(N2BoxCox)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

BC.norm.Site <- BC.N2 %>%
  group_by(Site) %>%
  summarise(SW.pvalue = shapiro.test(N2BoxCox)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

BC.norm.Habitat <- BC.N2 %>%
  group_by(Habitat) %>%
  summarise(SW.pvalue = shapiro.test(N2BoxCox)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))


##Below section added in March 2017 to check the assumptions with the knowledge that you're supposed to check normality of RESIDUALS rather than raw data. Run on BoxCox transformed values as well as for untransformed values in previous section.

#Setting up model based on interactive 3-way design and pulling out residuals.
BC.model3 <- lm(N2BoxCox ~ Season * Site * Habitat, data = BC.N2)
BC.resids3 <- residuals(BC.model3)
qqnorm(BC.resids3)
qqline(BC.resids3)

#BoxCox transformed N2 fluxes pass both Shapiro (when checking for normality of RESIDUALS) and Levene!
shapiro.test(BC.resids3)
leveneTest(N2BoxCox ~ Season * Site * Habitat, data = BC.N2)

#Checking 2-way model of same. This is the more relevant model because we ultimately ended up dropping CoreName/Habitat as a significant variable and instead exploring the difference among season and sites.
BC.model2 <- lm(N2BoxCox ~ Season * Site, data = BC.N2)
BC.resids2 <- residuals(BC.model2)
qqnorm(BC.resids2)
qqline(BC.resids2)

#Fails both Shapiro and Levene when Habitat is dropped, possibly b/c Site is so off... Or because the levels of grouping in this scenario are weird?
shapiro.test(BC.resids2)
leveneTest(N2BoxCox ~ Season * Site, data = BC.N2)

BC.season.model <- lm(N2BoxCox ~ Season, data = BC.N2)
shapiro.test(residuals(BC.season.model))

BC.site.model <- lm(N2BoxCox ~ Site, data = BC.N2)
shapiro.test(residuals(BC.site.model))

BC.habitat.model <- lm(N2BoxCox ~ Habitat, data = BC.N2)
shapiro.test(residuals(BC.habitat.model))

#Transformed data pass heterosked test when analyzed separately
leveneTest(N2BoxCox ~ Site, data = BC.N2)
leveneTest(N2BoxCox ~ Season, data = BC.N2)

#Boxplots of Site, Season, and Site*Season. The first two look generally ok- variances aren't dead-on equal but there don't seem to be egregious problems. The combo graph, not so much. I can't find a clear-cut answer as to whether, for a 2-way ANOVA, the variances need to be equal based on the 2-way groupings. However, there aren't major conclusions based on this 2-way ANOVA (the 3-way is more important), so maybe it's not a dealbreaker.
ggplot(BC.N2, aes(Site, N2BoxCox)) + geom_boxplot()
ggplot(BC.N2, aes(Season, N2BoxCox)) + geom_boxplot()
boxplot(N2BoxCox ~ Site * Season, data = BC.N2)

#Checking boxplots for the untransformed data
ggplot(basic.N2, aes(Site, N2Flux)) + geom_boxplot()
ggplot(basic.N2, aes(Season, N2Flux)) + geom_boxplot()
boxplot(N2Flux ~ Site * Season, data = basic.N2)

```

Running ANOVAs on the Box Cox transformed N2 flux values.
```{r DNF.anovas}

#One-way ANOVA by Season
season.anova <- aov(N2BoxCox ~ Season, data = BC.N2)
summary(season.anova)
TukeyHSD(season.anova)

#One-way ANOVA by Site
site.anova <- aov(N2BoxCox ~ Site, data = BC.N2)
summary(site.anova)
TukeyHSD(site.anova)

#One-way ANOVA by Core Name confirms that none of them are significantly different from each other
#More appropriate to use Habitat as grouping, which will be employed going forward
CoreName.anova <- aov(N2BoxCox ~ CoreName, data = BC.N2)
summary(CoreName.anova)
TukeyHSD(CoreName.anova)

#One-way ANOVA by Habitat
habitat.anova <- aov(N2BoxCox ~ Habitat, data = BC.N2)
summary(habitat.anova)
TukeyHSD(habitat.anova)

#Run ANOVA treating Season & Site independently
indep.anova <- aov(N2BoxCox ~ Season + Site, data = BC.N2)
summary(indep.anova)
TukeyHSD(indep.anova)

#3-way ANOVA with interaction between Season & Habitat
#Habitat was not significant, so it was dropped for refined subsequent ANOVA
interact.anova <- aov(N2BoxCox ~  Habitat * Site * Season, data = BC.N2)
summary(interact.anova)
TukeyHSD(interact.anova)

#2-way interactive ANOVA with Site & Season
interact2 <- aov(N2BoxCox ~ Site * Season, data = BC.N2)
summary(interact2)
TukeyHSD(interact2)

nested.anova <- aov(N2BoxCox ~ (Season + Site) / Habitat, data = BC.N2)
summary(nested.anova)
TukeyHSD(nested.anova)

```

Graphing DNE.
```{r DNE.graphs}

DNE %>%
  ggplot(aes(Site, DNE, fill = CoreName)) +
  geom_bar(stat = "identity", position = "dodge") + facet_grid(Season ~ .)

```

Creating linear correlations for 
```{r linear.models}

#Eliminate Summer 2015 data points
no.summer15 <- all.N2[!all.N2$Season == "Summer15", ]

#Eliminate LoRef and HiRef
basic.N2 <- no.summer15[!no.summer15$Habitat == "LoRef", ]
basic.N2 <- basic.N2[!basic.N2$Habitat == "HiRef", ]

#Calculate summary stats based on core type
type.basic.N2 <- full.summary(basic.N2)

#Creating linear regression for untransformed data and plotting results
reg1 <- lm(formula = N2Flux ~ Age, data = basic.N2)
summary(reg1)
par(mfrow = c(2,2))
plot(reg1)

#Graphing relationship b/t age and N2 flux
formula <- y ~ x

p1 <- ggplot(basic.N2, aes(Age, N2Flux, colour = Habitat))
p1 + geom_point() +
  geom_smooth(method = "lm", formula = formula, se = F) +
  stat_poly_eq(formula = formula,
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               parse = T) +
  stat_fit_glance(method = "lm",
                  geom = "text",
                  aes(label = paste("P-value =", signif(..p.value.., digits = 4), sep = "")),
                  label.x.npc = "right")

basic.N2 %>%
  ggplot(aes(Age, N2Flux, colour = Habitat)) +
  geom_point() +
  facet_grid(Season ~ .) +
  geom_smooth(method = "lm", formula = formula, se = F) +
  stat_poly_eq(formula = formula,
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               parse = T) +
  stat_fit_glance(method = "lm",
                  geom = "text",
                  aes(label = paste("P-value =", signif(..p.value.., digits = 4), sep = "")),
                  label.x.npc = "right")

basic.N2 %>%
  ggplot(aes(Age, N2Flux, colour = Season)) +
  geom_point() +
  facet_grid(Habitat ~ .) +
  geom_smooth(method = "lm", formula = formula, se = F) +
  stat_poly_eq(formula = formula,
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               parse = T) +
  stat_fit_glance(method = "lm",
                  geom = "text",
                  aes(label = paste("P-value =", signif(..p.value.., digits = 4), sep = "")),
                  label.x.npc = "right")

basic.N2 %>%
  ggplot(aes(Age, N2Flux, colour = CoreName)) +
  geom_point() +
  facet_grid(Season ~ .) +
  geom_smooth(method = "lm", formula = formula, se = F) +
  stat_poly_eq(formula = formula,
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               parse = T) +
  stat_fit_glance(method = "lm",
                  geom = "text",
                  aes(label = paste("P-value =", signif(..p.value.., digits = 4), sep = "")),
                  label.x.npc = "right")
  
```

Early attempts to achieve normal distribution within N2 flux rates using a log transformation. Other transformations were attempted (ie square root) but not recorded here because of complete failure.  Ultimately, Box Cox was used for transforming N2 fluxes. The below code has been saved in case it's necessary to return to it.
```{r failed.transformations}

#Eliminate Summer 2015 data points
no.summer15 <- all.N2[!all.N2$Season == "Summer15", ]

#Eliminate LoRef and HiRef
no.summer15 <- no.summer15[!no.summer15$Habitat == "LoRef", ]
no.summer15 <- no.summer15[!no.summer15$Habitat == "HiRef", ]

#Create column with log of positive N2 flux values (added 21 to make them all >0)
log.Site <- no.summer15 %>%
  mutate(log_N2Flux = log(N2Flux + 21, 10))

#Log-transformed values fail 2 tests for heteroskedasticity
bartlett.test(log_N2Flux ~ Site, data = log.Site)
leveneTest(log_N2Flux ~ Site, data = log.Site)

#2 sites fail Shapiro-Wilk test for normality
test.norm.log.Site <- log.Site %>%
  group_by(Site) %>%
  summarise(SW.pvalue = shapiro.test(log_N2Flux)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

#oysters fail Shapiro-Wilk test for nomality
test.norm.log.Habitat <- log.Site %>%
  group_by(Habitat) %>%
  summarise(SW.pvalue = shapiro.test(log_N2Flux)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

#Exploring log-transformed values w/ histograms by Site
#Data are right-skewed, altho general bell shape is slightly better
log.Site %>%
  ggplot(aes(log_N2Flux)) +
  geom_histogram(stat = "bin", binwidth = .05) +
  facet_grid(Season ~ .)

#QQ plot of log-transformed values also looks questionable
p2 <- ggplot(log.Site, aes(sample = log_N2Flux)) 
p2 + stat_qq(aes(colour = Site))

```

```{r export.csv}

#CSVs for the Box Cox transformed N2 flux values

write.csv(use.lambda, "PRIMER\\clean\\N2_BoxCoxTransform.csv", row.names = F)
write.csv(use.lambda.type, "PRIMER\\clean\\N2_BoxCoxTransform-by-type.csv", row.names = F)

```

