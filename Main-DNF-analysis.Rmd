---
title: "Main DNF Analysis"
author: "Kathleen Onorevole"
date: "August 18, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Remember to set working directory**

Load the packages required for these analyses. Also source the functions script.
```{r libraries}

library("plyr")
library("dplyr")
library("ggplot2")
library("ggpmisc")
library("lmtest")
library("car")
library("MASS")

source("functions.R")

```

Read in relevant data sets. These should all be taken from the CLEAN folders, which are housed in my master R Markdown folder. The raw data have been processed in separate R Markdown documents; see those files for details. Each parameter has its own folder within the parent folder.
```{r read.in}

all.N2 <- read.csv("N2-flux\\clean\\N2-flux-by-core_with-summer15.csv", header = T, stringsAsFactors = F)

DNE <- read.csv("DNE\\clean\\DNE-clean_no-summer15_all-sites.csv", header = T, stringsAsFactors = F)

```

Set the distinguishing labels as factors and implementing the preferred order. Uses set.factors function written by me.
Also eliminate Summer 2015 and Lo/Hi Ref cores as neither will be used in basic thesis analysis. (Do not match sampling scheme and thereby mess up statistics.) Will deal with these in a separate R Markdown doc if necessary.
``` {r order.variables}

#Uses basic factor settings to input NA for Lo/Hi Ref and Summer 2015 cores
all.N2 <- set.factors.basic(all.N2)

all.N2$Age <- as.numeric(all.N2$Age)
all.N2$Habitat <- factor(all.N2$Habitat, levels = c("oyster", "marsh", "Ref"))

#Eliminate Lo/Hi Ref and Summer 2015 by getting rid of NAs
basic.N2 <- na.omit(all.N2)

DNE <- set.factors.basic(DNE)
DNE <- na.omit(DNE)

```

Begin by exploring original N2 flux data set for normal distribution and heteroskedasticity. Essentially, every measure fails.
``` {r normal.checks}

#Fails Bartlett Test when grouped by Site and Season; Habitat is ok
bartlett.test(N2Flux ~ Site, data = basic.N2)
bartlett.test(N2Flux ~ Season, data = basic.N2)
bartlett.test(N2Flux ~ Habitat, data = basic.N2)

#Interestingly, passes Levene Test for Site and Habitat; fails for Season (change 2nd parameter after ~ to explore)
leveneTest(N2Flux ~ Site, data = basic.N2)

#Boxplot looks ok but there are definite outliers (change 2nd parameter as above)
boxplot(N2Flux ~ Season, data = basic.N2)

#All seasons except winter fail Shapiro-Wilk test
test.norm.Season <- basic.N2 %>%
  group_by(Season) %>%
  summarise(SW.pvalue = shapiro.test(N2Flux)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

#All sites except Carrot fail Shapiro-Wilk
test.norm.Site <- basic.N2 %>%
  group_by(Site) %>%
  summarise(SW.pvalue = shapiro.test(N2Flux)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

#Histograms do not appear normal (again, change grouping parameter if desired)
basic.N2 %>%
  ggplot(aes(N2Flux)) +
  geom_histogram(stat = "bin", binwidth = 5) +
  facet_grid(Season ~ .)

#QQ plot lines by Site are not satisfactorily straight
p1 <- ggplot(basic.N2)
p1 + stat_qq(aes(sample = N2Flux, colour = Site)) + geom_smooth(aes(colour = Site), method = "lm")

```

Normality checks largely failed. Various transformations were attempted (see failed.transformations section of this R Markdown doc) and I ultimately decided to use the Box Cox transformation. The below code identifies the optimal lambda value, applies the transformation, and checks for normality/heteroskedasticity.
``` {r BoxCox.transform}

#Start by finding the optimal value of lambda

#Create a column with positive values of N2 by adding 21 to each flux
positive.N2 <- mutate(basic.N2,
                  PosN2 = N2Flux + 21)
#Create a log-likelihood graph using a command from the MASS package
bctrans <- boxcox(PosN2 ~ Age, data = positive.N2,
                    lambda = seq(0, 1, by = 0.1))
#Identify the maximum likelihood value
which.max(bctrans$y)
#Use that maximum likelihood value (from the y axis) to determine the associated lambda (on the x axis)
bctrans$x[which.max(bctrans$y)]

#Take the variable to the power of the lambda to perform the transformation!
BC.N2 <- mutate(positive.N2,
                     N2BoxCox = (((PosN2 ^ 0.454) - 1) / 0.454))

#Calculate transformed N2 flux values by core type
BC.N2.type <- ddply(BC.N2, c("Season", "Site", "CoreName", "Habitat", "Age"), summarise,
                         Avg_N2BoxCox = mean(N2BoxCox))

#Histogram and QQ plots look much better
hist(BC.N2$N2BoxCox)
qqnorm(BC.N2$N2BoxCox)
qqline(BC.N2$N2BoxCox)

#I believe this plot visualizes the variance, which looks more even
plot(BC.N2$N2BoxCox)

#Visualizing the regression with the Box Cox transformation
reg1 <- lm(N2BoxCox ~ Age, BC.N2)
par(mfrow = c(2,2))
plot(reg1)

#Transformed values pass Bartlett Test except for when grouped by Site (p = 0.01)
#Pass Levene Test for every grouping
#Change grouping variable after ~ to view various outcomes
bartlett.test(N2BoxCox ~ Habitat, BC.N2)
leveneTest(N2BoxCox ~ Habitat, BC.N2)

#Transformed data passes Shapiro-Wilk test for all groupings except Army & oysters
BC.norm.Season <- BC.N2 %>%
  group_by(Season) %>%
  summarise(SW.pvalue = shapiro.test(N2BoxCox)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

BC.norm.Site <- BC.N2 %>%
  group_by(Site) %>%
  summarise(SW.pvalue = shapiro.test(N2BoxCox)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

BC.norm.Habitat <- BC.N2 %>%
  group_by(Habitat) %>%
  summarise(SW.pvalue = shapiro.test(N2BoxCox)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

```

Running ANOVAs on the Box Cox transformed N2 flux values.
```{r DNF.anovas}

#One-way ANOVA by Season
season.anova <- aov(N2BoxCox ~ Season, data = BC.N2)
summary(season.anova)
TukeyHSD(season.anova)

#One-way ANOVA by Site
site.anova <- aov(N2BoxCox ~ Site, data = BC.N2)
summary(site.anova)
TukeyHSD(site.anova)

#One-way ANOVA by Core Name confirms that none of them are significantly different from each other
#More appropriate to use Habitat as grouping, which will be employed going forward
CoreName.anova <- aov(N2BoxCox ~ CoreName, data = BC.N2)
summary(CoreName.anova)
TukeyHSD(CoreName.anova)

#One-way ANOVA by Habitat
habitat.anova <- aov(N2BoxCox ~ Habitat, data = BC.N2)
summary(habitat.anova)
TukeyHSD(habitat.anova)

#Run ANOVA treating Season & Site independently
indep.anova <- aov(N2Flux ~ Season + Site, data = BC.N2)
summary(indep.anova)
TukeyHSD(indep.anova)

#3-way ANOVA with interaction between Season & Habitat
#Habitat was not significant, so it was dropped for refined subsequent ANOVA
interact.anova <- aov(N2Flux ~  Habitat * Site * Season, data = BC.N2)
summary(interact.anova)
TukeyHSD(interact.anova)

#2-way interactive ANOVA with Site & Season
interact2 <- aov(N2Flux ~ Site * Season, data = BC.N2)
summary(interact2)
TukeyHSD(interact2)

nested.anova <- aov(N2Flux ~ (Season + Site) / Habitat, data = BC.N2)
summary(nested.anova)
TukeyHSD(nested.anova)

```

Graphing DNE.
``` {r DNE.graphs}

DNE %>%
  ggplot(aes(Site, DNE, fill = CoreName)) +
  geom_bar(stat = "identity", position = "dodge") + facet_grid(Season ~ .)

```

Creating linear correlations for 
``` {r linear.models}

#Eliminate Summer 2015 data points
no.summer15 <- all.N2[!all.N2$Season == "Summer15", ]

#Eliminate LoRef and HiRef
basic.N2 <- no.summer15[!no.summer15$Habitat == "LoRef", ]
basic.N2 <- basic.N2[!basic.N2$Habitat == "HiRef", ]

#Calculate summary stats based on core type
type.basic.N2 <- full.summary(basic.N2)

#Creating linear regression for untransformed data and plotting results
reg1 <- lm(formula = N2Flux ~ Age, data = basic.N2)
summary(reg1)
par(mfrow = c(2,2))
plot(reg1)

#Graphing relationship b/t age and N2 flux
formula <- y ~ x

p1 <- ggplot(basic.N2, aes(Age, N2Flux, colour = Habitat))
p1 + geom_point() +
  geom_smooth(method = "lm", formula = formula, se = F) +
  stat_poly_eq(formula = formula,
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               parse = T) +
  stat_fit_glance(method = "lm",
                  geom = "text",
                  aes(label = paste("P-value =", signif(..p.value.., digits = 4), sep = "")),
                  label.x.npc = "right")

basic.N2 %>%
  ggplot(aes(Age, N2Flux, colour = Habitat)) +
  geom_point() +
  facet_grid(Season ~ .) +
  geom_smooth(method = "lm", formula = formula, se = F) +
  stat_poly_eq(formula = formula,
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               parse = T) +
  stat_fit_glance(method = "lm",
                  geom = "text",
                  aes(label = paste("P-value =", signif(..p.value.., digits = 4), sep = "")),
                  label.x.npc = "right")

basic.N2 %>%
  ggplot(aes(Age, N2Flux, colour = Season)) +
  geom_point() +
  facet_grid(Habitat ~ .) +
  geom_smooth(method = "lm", formula = formula, se = F) +
  stat_poly_eq(formula = formula,
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               parse = T) +
  stat_fit_glance(method = "lm",
                  geom = "text",
                  aes(label = paste("P-value =", signif(..p.value.., digits = 4), sep = "")),
                  label.x.npc = "right")

basic.N2 %>%
  ggplot(aes(Age, N2Flux, colour = CoreName)) +
  geom_point() +
  facet_grid(Season ~ .) +
  geom_smooth(method = "lm", formula = formula, se = F) +
  stat_poly_eq(formula = formula,
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               parse = T) +
  stat_fit_glance(method = "lm",
                  geom = "text",
                  aes(label = paste("P-value =", signif(..p.value.., digits = 4), sep = "")),
                  label.x.npc = "right")
  
```

Early attempts to achieve normal distribution within N2 flux rates using a log transformation. Other transformations were attempted (ie square root) but not recorded here because of complete failure.  Ultimately, Box Cox was used for transforming N2 fluxes. The below code has been saved in case it's necessary to return to it.
``` {r failed.transformations}

#Eliminate Summer 2015 data points
no.summer15 <- all.N2[!all.N2$Season == "Summer15", ]

#Eliminate LoRef and HiRef
no.summer15 <- no.summer15[!no.summer15$Habitat == "LoRef", ]
no.summer15 <- no.summer15[!no.summer15$Habitat == "HiRef", ]

#Create column with log of positive N2 flux values (added 21 to make them all >0)
log.Site <- no.summer15 %>%
  mutate(log_N2Flux = log(N2Flux + 21, 10))

#Log-transformed values fail 2 tests for heteroskedasticity
bartlett.test(log_N2Flux ~ Site, data = log.Site)
leveneTest(log_N2Flux ~ Site, data = log.Site)

#2 sites fail Shapiro-Wilk test for normality
test.norm.log.Site <- log.Site %>%
  group_by(Site) %>%
  summarise(SW.pvalue = shapiro.test(log_N2Flux)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))

#oysters fail Shapiro-Wilk test for nomality
test.norm.log.Habitat <- log.Site %>%
  group_by(Habitat) %>%
  summarise(SW.pvalue = shapiro.test(log_N2Flux)$p.value) %>%
  mutate(Result = ifelse(SW.pvalue < 0.05, "Normal", "Non-Normal"))

#Exploring log-transformed values w/ histograms by Site
#Data are right-skewed, altho general bell shape is slightly better
log.Site %>%
  ggplot(aes(log_N2Flux)) +
  geom_histogram(stat = "bin", binwidth = .05) +
  facet_grid(Season ~ .)

#QQ plot of log-transformed values also looks questionable
p2 <- ggplot(log.Site, aes(sample = log_N2Flux)) 
p2 + stat_qq(aes(colour = Site))

```

``` {r export.csv}

#CSVs for the Box Cox transformed N2 flux values

write.csv(use.lambda, "PRIMER\\clean\\N2_BoxCoxTransform.csv", row.names = F)
write.csv(use.lambda.type, "PRIMER\\clean\\N2_BoxCoxTransform-by-type.csv", row.names = F)

```

