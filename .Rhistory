depth_dist <- ggplot(diamonds, aes(depth)) + xlim(58, 68)
install.packages("ggplot2")
library("ggplot2")
depth_dist <- ggplot(diamonds, aes(depth)) + xlim(58, 68)
geom_histogram(aes(y = ..density..), binwidth = 0.1) + facet_grid(cut ~ .)
depth_dist +
geom_histogram(aes(y = ..density..), binwidth = 0.1) + facet_grid(cut ~ .)
geom_histogram(aes(y = ..density..), binwidth = 0.5) + facet_grid(cut ~ .)
depth_dist +
geom_histogram(aes(y = ..density..), binwidth = 0.5) + facet_grid(cut ~ .)
depth_dist +
geom_histogram(aes(y = ..density..), binwidth = 0.1) + facet_grid(cut ~ .)
depth_dist + geom_histogram(aes(fill = cut), binwidth = 0.1, position = "fill")
depth_dist + geom_freqpoly(aes(y = ..density.., colour = cut), bindwidth = 0.1)
depth_dist + geom_freqpoly(aes(y = ..density.., colour = cut), binwidth = 0.1)
qplot(cut, depth, data = diamonds, geom = "boxplot")
qplot(carat, depth, data = diamonds, geom = "boxplot",
group = round_any(carat, 0.1, floor), xlim = c(0,3))
?round_any
qplot(carat, depth, data = diamonds, geom = "boxplot",
group = round_any(carat, 0.1, floor), xlim = c(0,3))
qplot(carat, depth, data = diamonds, geom = "boxplot", group = round_any(carat, 0.1, floor), xlim = c(0,3))
qplot(carat, depth, data = diamonds, geom = "boxplot",
+ group = round_any(carat, 0.1, floor), xlim = c(0,3))
qplot(carat, depth, data = diamonds, geom = "boxplot", +
group = round_any(carat, 0.1, floor), xlim = c(0,3))
qplot(carat, depth, data = diamonds, geom = "boxplot",
group = round_any(carat, 0.1, floor), xlim = c(0,3))
?round_any
install.packages("plyr")
install.packages("splus2R")
install.packages("rmarkdown")
library("rmarkdown")
citation()
citation(package = "rpart")
install.packages(c("BH", "car", "colorspace", "DBI", "digest", "evaluate", "ggplot2", "ggpmisc", "ggrepel", "jsonlite", "knitr", "lubridate", "mnormt", "polynom", "psych", "quantreg", "R6", "Rcpp", "reshape2", "rmarkdown", "rpart.plot", "scales", "SparseM", "splus2R", "stringi", "yaml", "zoo"))
install.packages("installr")
library("installr")
updateR()
setwd("E:/R Markdown")
library(plyr)
library(dplyr)
library(car)
library(ggplot2)
library(ggpmisc)
library(lattice)
library(grid)
library(reshape2)
library(RColorBrewer)
library(gtable)
library(gridExtra)
library(cowplot)
library(MASS)
source("functions.R")
setwd("E:/R Markdown")
library(plyr)
library(dplyr)
library(car)
library(ggplot2)
library(ggpmisc)
library(lattice)
library(grid)
library(reshape2)
library(RColorBrewer)
library(gtable)
library(gridExtra)
library(cowplot)
library(MASS)
source("functions.R")
library(plyr)
library(dplyr)
library(car)
library(ggplot2)
library(ggpmisc)
library(lattice)
library(grid)
library(reshape2)
library(RColorBrewer)
library(gtable)
library(gridExtra)
library(cowplot)
library(MASS)
source("functions.R")
annual.data <- read.csv("PRIMER\\raw\\annual-data_all-seasons_all-sites.csv", header = T, stringsAsFactors = F)
all.avgs <- read.csv("PRIMER\\raw\\all-data_annual-avg_all-sites.csv", header = T, stringsAsFactors = F)
spring <- read.csv("PRIMER\\raw\\all-data_spring15_all-sites.csv", header = T, stringsAsFactors = F)
sed.data <- read.csv("PRIMER\\raw\\sed-data_spring15_all-sites.csv", header = T, stringsAsFactors = F)
View(annual.data)
all.avgs.nona <- na.omit(all.avgs)
all.avgs.nona$Site <- factor(all.avgs.nona$Site, levels = c("IMS", "Carrot", "NOAA", "Army"))
all.avgs.nona$CoreName <- factor(all.avgs.nona$CoreName, levels = c("LO", "HO", "MM"))
all.avgs.nona$Habitat <- factor(all.avgs.nona$Habitat, levels = c("oyster", "marsh"))
sed.data$Site <- factor(sed.data$Site, levels = c("IMS", "Carrot", "NOAA", "Army"))
sed.data$CoreName <- factor(sed.data$CoreName, levels = c("LO", "HO", "LM", "MM", "HM", "Ref"))
sed.data$Habitat <- factor(sed.data$Habitat, levels = c("oyster", "marsh", "Ref"))
annual.data <- add.sandflat(annual.data)
annual.data <- add.age(annual.data)
annual.data$Age <- as.numeric(annual.data$Age)
annual.data <- set.factors.habitat(annual.data)
str(annual.data)
drops <- c("O2conc", "PercentInundation", "NOxFlux", "NH3Flux")
annual.fix <- annual.data[ , !(names(annual.data) %in% drops)]
annual.fix$Age <- factor(annual.fix$Age, levels = c("0", "2", "7", "20"))
annual.fix <- mutate(annual.fix,
PosN2 = N2Flux + 10)
#Create a log-likelihood graph using a command from the MASS package
bctrans <- boxcox(PosN2 ~ Age, data = annual.fix,
lambda = seq(0, 1, by = 0.1))
#Identify the maximum likelihood value
which.max(bctrans$y)
#Use that maximum likelihood value (from the y axis) to determine the associated lambda (on the x axis)
bctrans$x[which.max(bctrans$y)]
#Take the variable to the power of the lambda to perform the transformation!
annual.fix <- mutate(annual.fix,
N2BoxCox = (((PosN2 ^ 0.545) - 1) / 0.545))
bartlett.test(N2BoxCox ~ Site, data = annual.fix)
str(annual.fix)
trial <- add.num.age(annual.fix)
trial %>%
ggplot(aes(NumAge, N2BoxCox)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
View(annual.fix)
bctrans2 <- boxcox(SOD ~ Age, data = annual.fix,
lambda = seq(0, 1, by = 0.1))
#Identify the maximum likelihood value
which.max(bctrans2$y)
#Use that maximum likelihood value (from the y axis) to determine the associated lambda (on the x axis)
bctrans2$x[which.max(bctrans2$y)]
#Take the variable to the power of the lambda to perform the transformation!
annual.fix <- mutate(annual.fix,
SODBoxCox = (((SOD ^ 0.192) - 1) / 0.192))
test.norm.BCSOD <- annual.fix %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(SODBoxCox)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
View(test.norm.BCSOD)
annual.fixtemp <- mutate(annual.fix,
log.SOD = log(SOD, 10),
ln.SOD = log(SOD))
test.norm.BCSOD2 <- annual.fixtemp %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(log.SOD)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
View(test.norm.BCSOD2)
View(test.norm.BCSOD)
View(test.norm.BCSOD2)
bctrans2 <- boxcox(SOD ~ Age, data = annual.fix,
lambda = seq(0, 1, by = 0.1))
which.max(bctrans2$y)
bctrans2$x[which.max(bctrans2$y)]
annual.fix <- mutate(annual.fix,
SODBoxCox = (((SOD ^ 0.192) - 1) / 0.192))
View(annual.fix)
annual.fix <- mutate(annual.fix,
SODBoxCox = (((SOD ^ 0.192) - 1) / 0.192),
log.SOD = log(SOD, 10),
ln.SOD = log(SOD))
View(annual.fix)
test.norm.logSOD <- annual.fix %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(log.SOD)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
test.norm.BCSOD <- annual.fix %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(SODBoxCox)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
View(test.norm.logSOD)
View(test.norm.BCSOD)
test.norm.lnSOD <- annual.fix %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(ln.SOD)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
View(test.norm.lnSOD)
View(test.norm.lnSOD)
View(test.norm.logSOD)
View(test.norm.BCSOD)
View(annual.fix)
View(sed.data)
trial %>%
ggplot(aes(NumAge, N2BoxCox)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
quad.formula <- y ~ poly(x,2)
trial %>%
ggplot(aes(NumAge, N2BoxCox)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
model <- lm(trial$N2BoxCox ~ poly(trial$NumAge,2))
summary(model)
trial %>%
ggplot(aes(NumAge, log.SOD)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
View(trial)
#Remember: Check for homoegeneity of variances w Bartlett test. If p>0.05, cannot reject null that variance is same -- so the sample passes.
#Checking for normality using Shapiro-Wilk with previously-written code to spell out results. Shapiro-Wilk tests AGAINST assumption of normality: aka, if p<0.05, the samples are likely to be non-normal. This is confusing which is why I've written the code.
### ANNUAL N2 FLUX ###
#Fails Bartlett, p = 0.03
bartlett.test(N2Flux ~ Site, data = annual.data)
#Everything passes except for Army...
test.norm.N2 <- annual.data %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(N2Flux)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
##Use Box Cox transformation to attempt correction since log transformation failed
#Create annual.fix data frame to be used for adding transformed values. Eliminate all but relevant columns for simplicity; transformed values will be added as new columns. Also convert Age to a factor b/c it was previously numeric.
drops <- c("O2conc", "PercentInundation", "NOxFlux", "NH3Flux")
annual.fix <- annual.data[ , !(names(annual.data) %in% drops)]
annual.fix$Age <- factor(annual.fix$Age, levels = c("0", "2", "7", "20"))
#Start by finding the optimal value of lambda
#Create a column with positive values of N2 by adding 10 to each flux
annual.fix <- mutate(annual.fix,
PosN2 = N2Flux + 10)
#Create a log-likelihood graph using a command from the MASS package
bctrans <- boxcox(PosN2 ~ Age, data = annual.fix,
lambda = seq(0, 1, by = 0.1))
#Identify the maximum likelihood value
which.max(bctrans$y)
#Use that maximum likelihood value (from the y axis) to determine the associated lambda (on the x axis)
bctrans$x[which.max(bctrans$y)]
#Take the variable to the power of the lambda to perform the transformation!
annual.fix <- mutate(annual.fix,
N2BoxCox = (((PosN2 ^ 0.545) - 1) / 0.545))
#Passes Bartlett, p = 0.057
bartlett.test(N2BoxCox ~ Site, data = annual.fix)
#Army still fails, but is closer: p = 0.022 vs 0.0007
test.norm.BCN2 <- annual.fix %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(N2BoxCox)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
### SUMMER N2 FLUX ###
#subsetting annual.fix to create a new data frame with only tranformed summer data for testing
summer.BCtest <- annual.fix %>%
filter(Season == "Summer") %>%
group_by(Site)
#Running checks on transformed summer N2 Flux data-- passes all
bartlett.test(N2BoxCox ~ Site, data = summer.BCtest)
test.norm.BCsumN2 <- summer.BCtest %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(N2BoxCox)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
#Similar to above but only looking at UNTRANSFORMED data just to confirm that there are some violations of assumptions unless the data are transformed.
#Create subset data frame with only summer data to run test on N2 Flux, to ultimately add a dotted line for summer N2 flux trajectory. This is a modified version of the broader seasonal regressions that were conducted earlier in analysis to explore trends.
summer.test <- annual.data %>%
filter(Season == "Summer") %>%
group_by(Site)
#passes Bartlett
bartlett.test(N2Flux ~ Site, data = summer.test)
#Carrot fails normality
test.norm.sumN2 <- summer.test %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(N2Flux)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
### ANNUAL SOD ###
#Passes Bartlett!
bartlett.test(SOD ~ Site, data = annual.data)
#Army & Carrot fail normality.
test.norm.SOD <- annual.data %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(SOD)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
#Implement a Box Cox transformation to correct
#Start by finding the optimal value of lambda
#Create a log-likelihood graph using a command from the MASS package
bctrans2 <- boxcox(SOD ~ Age, data = annual.fix,
lambda = seq(0, 1, by = 0.1))
#Identify the maximum likelihood value
which.max(bctrans2$y)
#Use that maximum likelihood value (from the y axis) to determine the associated lambda (on the x axis)
bctrans2$x[which.max(bctrans2$y)]
#Take the variable to the power of the lambda to perform the transformation! Also adding columns for log transformation (ln did not produce compelling normality results).
annual.fix <- mutate(annual.fix,
SODBoxCox = (((SOD ^ 0.192) - 1) / 0.192),
log.SOD = log(SOD, 10))
#Passes Bartlett still. Normality is better, and results depend on transformation. IMS fails for log and Army fails for BoxCox. Both results are better than untransformed tho (p = 0.02 or 0.01 vs 0.000002).
test.norm.logSOD <- annual.fix %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(log.SOD)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
test.norm.BCSOD <- annual.fix %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(SODBoxCox)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
### ANNUAL SOM ###
#fails Bartlett test, p = 1.2 E-8
bartlett.test(PercentOM ~ Site, data = annual.data)
#IMS & Carrot fail normality
test.norm.SOM <- annual.data %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(PercentOM)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
#Added a column SOM which is PercentOM changed to a proportion rather than a %.
#First attempted BoxCox transform but it didn't work- possibly b/c it's a %?
#Attempt square root and arcsin transformation, which wasn't helpful: still failed same checks. Then attempted logit transformation, which was more functional.
annual.fix <- mutate(annual.fix,
SOM = PercentOM / 100,
sqrootSOM = sqrt(SOM),
arcsinSOM = asin(sqrootSOM),
logitSOM = log(SOM / (1-SOM)))
#Logit transform fails Barlett but better (p = 0.002) and all pass normality
bartlett.test(logitSOM ~ Age, annual.fix2)
test.norm.logitSOM <- annual.fix2 %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(logitSOM)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
### SPRING BULK DENSITY ###
#Fails Bartlett, p = 0.01
bartlett.test(BulkDensity ~ Site, data = sed.data)
#All pass
test.norm.BD <- sed.data %>%
group_by(Site) %>%
summarise(SW.pvalue = shapiro.test(BulkDensity)$p.value) %>%
mutate(Result = ifelse(SW.pvalue > 0.05, "Normal", "Non-Normal"))
#Unable to find a transformation that passes the assumptions using the standard set of transformations and Box Cox. (Got same error as with SOM for bulk density for Box Cox, where max value was 100 and resulting x value was 0. Not sure what's causing that to happen, but it's probably something theoretical.) Attempted a bunch of different transformations below, but nothing worked. I have deleted most of the code for subsequent Bartlett & normality tests for simplicity.
sed.fix <- mutate(sed.data,
log.BD = log(BulkDensity, 10),
sqroot.BD = sqrt(BulkDensity),
BDsquared = BulkDensity ^ 2,
ln.BD = log(BulkDensity),
cuberoot.BD = BulkDensity ^ (1/3),
logplus.BD = log(BulkDensity + 1, 10))
sed.fix$Age <- factor(sed.fix$Age, levels = c("0", "2", "7", "20"))
bartlett.test(log.BD ~ Site, sed.fix)
sed.fix <- mutate(sed.data,
log.BD = log(BulkDensity, 10),
sqroot.BD = sqrt(BulkDensity),
BDsquared = BulkDensity ^ 2,
ln.BD = log(BulkDensity),
cuberoot.BD = BulkDensity ^ (1/3),
logplus.BD = log(BulkDensity + 1, 10))
View(sed.fix)
trial %>%
ggplot(aes(NumAge, log.SOD)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
trial <- add.num.age(annual.fix)
curve but units are VERY different.
trial %>%
ggplot(aes(NumAge, log.SOD)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
trial %>%
ggplot(aes(NumAge, N2Flux)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
model2 <- lm(trial$log.SOD ~ poly(trial$NumAge, 2))
summary(model2)
trial %>%
ggplot(aes(NumAge, SOD)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
annual.data %>%
ggplot(aes(Age, SOD)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ log(x + .001), size = 2) +
stat_poly_eq(formula = y ~ log(x + .001),
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = T) +
stat_fit_glance(method = "lm",
method.args = list(formula = y ~ log(x + .001),
geom = "text",
aes(label = paste("P-value =", signif(..p.value.., digits = 4), sep = "")),
label.x.npc = "right"))
trial %>%
ggplot(aes(NumAge, logitSOM)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
model3 <- lm(trial$logitSOM ~ poly(trial$NumAge, 2))
summary(model3)
trial %>%
ggplot(aes(NumAge, SOM)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
trial %>%
ggplot(aes(NumAge, BulkDensity)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
trial2 %>%
ggplot(aes(NumAge, Bulk Density)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
trial2 %>%
ggplot(aes(NumAge, BulkDensity)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
trial2 <- add.num.age(sed.data)
trial2 %>%
ggplot(aes(NumAge, BulkDensity)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula)
model5 <- lm(trial2$BulkDensity ~ poly(trial2$NumAge, 2))
summary(model5)
melted.annual <- melt(annual.data, measure.vars = c("O2conc", "SOD", "PercentOM", "PercentInundation", "NOxFlux", "NH3Flux", "N2Flux"))
melted.1 <- melted.annual[melted.annual$variable == "SOD" | melted.annual$variable == "N2Flux", ]
melted.1 %>%
filter(variable == "N2Flux") %>%
ggplot(aes(Age, value)) +
geom_point() +
geom_smooth(method = "lm", formula = quad.formula) +
stat_poly_eq(formula = y ~ poly(x,2),
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = T) +
stat_fit_glance(method = "lm",
method.args = list(formula = quad.formula),
geom = "text",
aes(label = paste("P-value =", signif(..p.value.., digits = 4), sep = "")),
label.x.npc = "right")
View(melted.1)
View(melted.annual)
